{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98d3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install bert-extractive-summarizer\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97813dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "# load train and validation data\n",
    "text_df = pd.read_csv('rrs-mimiciii/all/train.findings.tok', sep=\"delimiter\", header=None, names=['text'])\n",
    "summary_df = pd.read_csv('rrs-mimiciii/all/train.impression.tok',sep='delimiter', header=None, names=['summary'])\n",
    "train_df = pd.concat([text_df,summary_df], axis=1, join='inner')\n",
    "\n",
    "text_df = pd.read_csv('rrs-mimiciii/all/validate.findings.tok', sep=\"delimiter\", header=None, names=['text'])\n",
    "summary_df = pd.read_csv('rrs-mimiciii/all/validate.impression.tok',sep='delimiter', header=None, names=['summary'])\n",
    "valid_df = pd.concat([text_df,summary_df], axis=1, join='inner')\n",
    "\n",
    "text_df = pd.read_csv('rrs-mimiciii/all/test.findings.tok', sep=\"delimiter\", header=None, names=['text'])\n",
    "summary_df = pd.read_csv('rrs-mimiciii/all/test.impression.tok',sep='delimiter', header=None, names=['summary'])\n",
    "test_df = pd.concat([text_df,summary_df], axis=1, join='inner')\n",
    "\n",
    "train_dataset = datasets.Dataset.from_dict({\"text\":train_df['text'].tolist(),\"summary\":train_df['summary'].tolist()})\n",
    "val_dataset = datasets.Dataset.from_dict({\"text\":valid_df['text'].tolist(),\"summary\":valid_df['summary'].tolist()})\n",
    "\n",
    "#train_dataset = train_dataset.select(range(512))\n",
    "#val_dataset = val_dataset.select(range(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2efc893e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BigBirdModel' from 'transformers' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_746401/2867629185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from transformers import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load model, model config and tokenizer via Transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/summarizer/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummarizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerSummarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Summarizer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TransformerSummarizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/summarizer/bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from transformers import (AlbertModel, AlbertTokenizer, BartModel, BigBirdModel, BigBirdTokenizer,\n\u001b[0m\u001b[1;32m      5\u001b[0m                           \u001b[0mBartTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                           \u001b[0mCamembertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCamembertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCTRLModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BigBirdModel' from 'transformers' (unknown location)"
     ]
    }
   ],
   "source": [
    "#from transformers import *\n",
    "from transformers import AutoConfig, AutoTokenizer,AutoModel\n",
    "from summarizer import Summarizer\n",
    "\n",
    "# Load model, model config and tokenizer via Transformers\n",
    "custom_config = AutoConfig.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "custom_config.output_hidden_states=True\n",
    "custom_tokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "custom_model = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', config=custom_config)\n",
    "\n",
    "model = Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e9439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
